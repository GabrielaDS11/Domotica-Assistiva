{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Comic San ML\"><font size=3>Topic modeling is an unsupervised technique that intends to analyze large volumes of text data by clustering the documents into groups. In the case of topic modeling, the text data do not have any labels attached to it. Rather, topic modeling tries to group the documents into clusters based on similar characteristics.</font></p>\n",
    "\n",
    "https://stackabuse.com/python-for-nlp-topic-modeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4B0082;font-family:Comic Sans MS;\">Latent Dirichlet Allocation (LDA)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Documents that have similar words usually have the same topic = Documents are probability distributions over latent topics\n",
    "2. Documents that have groups of words frequently occuring together usually have the same topic = Topics are probability distributions over words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimento</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>Retorno de alunos às aulas presenciais deverá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>O maior risco são os ônibus  eo metro e desde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>olá a todos, venho aqui encarecidamente pedir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Justiça nega pedido de retorno das aulas prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>n aguento mais o EAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimento                                               text\n",
       "0        neg  Retorno de alunos às aulas presenciais deverá ...\n",
       "1        neg  O maior risco são os ônibus  eo metro e desde ...\n",
       "2        neg  olá a todos, venho aqui encarecidamente pedir ...\n",
       "3        neg  Justiça nega pedido de retorno das aulas prese...\n",
       "4        pos                               n aguento mais o EAD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv(r'C:/Users/gabid/meus_desastres/NLTK/sentimentos.csv', sep=\";\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A minha escola é só de ensino médio e tem muitas salas vazias, e a direção irá separar vários alunos por turma e por em salas separadas, as minhas aulas estão previstas pra começar dia 10/08'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#create vocabulary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#creating a document-term matrix\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=stopwords)\n",
    "doc_term_matrix = count_vect.fit_transform(dataset['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26x41 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix\n",
    "#matrix com numero_de_amostras x numero_de_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=2, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=12, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "#The parameter n_components specifies the number of categories, or topics, that we want our text to be divided into.\n",
    "LDA = LatentDirichletAllocation(n_components=2, random_state=12)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agora\n",
      "aulas\n",
      "ônibus\n",
      "escolas\n",
      "pode\n",
      "adultos\n",
      "volta\n",
      "agora\n",
      "faculdade\n",
      "criança\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])\n",
    "\n",
    "#10 palavras aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 words with the highest probability for the first topic\n",
    "first_topic = LDA.components_[0]\n",
    "#Once sorted, the 10 words with the highest probabilities will now belong to the last 10 indexes of the array.\n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 16, 39, 13, 34, 22,  8, 30,  2,  4], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escola\n",
      "ficar\n",
      "volta\n",
      "escolas\n",
      "retorno\n",
      "lotados\n",
      "dia\n",
      "presenciais\n",
      "alunos\n",
      "aulas\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['escola', 'ficar', 'volta', 'escolas', 'retorno', 'lotados', 'dia', 'presenciais', 'alunos', 'aulas']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['pode', 'esposa', 'filho', 'papel', 'escolas', 'risco', 'gente', 'dificuldade', 'agora', 'ano']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's print the 10 words with highest probabilities for all topics:\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "#(numero de documentos, colunas de cada documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92004038, 0.07995962],\n",
       "       [0.86081269, 0.13918731],\n",
       "       [0.91452977, 0.08547023],\n",
       "       [0.89766282, 0.10233718],\n",
       "       [0.74295918, 0.25704082],\n",
       "       [0.74295918, 0.25704082],\n",
       "       [0.07968269, 0.92031731],\n",
       "       [0.80306846, 0.19693154],\n",
       "       [0.25429385, 0.74570615],\n",
       "       [0.1092917 , 0.8907083 ],\n",
       "       [0.92894398, 0.07105602],\n",
       "       [0.08360144, 0.91639856],\n",
       "       [0.89046753, 0.10953247],\n",
       "       [0.8595828 , 0.1404172 ],\n",
       "       [0.94209867, 0.05790133],\n",
       "       [0.498334  , 0.501666  ],\n",
       "       [0.38168368, 0.61831632],\n",
       "       [0.25428564, 0.74571436],\n",
       "       [0.07315335, 0.92684665],\n",
       "       [0.8282473 , 0.1717527 ],\n",
       "       [0.91469014, 0.08530986],\n",
       "       [0.0736568 , 0.9263432 ],\n",
       "       [0.10766324, 0.89233676],\n",
       "       [0.25279615, 0.74720385],\n",
       "       [0.17607882, 0.82392118],\n",
       "       [0.90790171, 0.09209829]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimento</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>Retorno de alunos às aulas presenciais deverá ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>O maior risco são os ônibus  eo metro e desde ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>olá a todos, venho aqui encarecidamente pedir ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Justiça nega pedido de retorno das aulas prese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>n aguento mais o EAD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg</td>\n",
       "      <td>É o certo né. EaD é um saco mas é mais seguro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg</td>\n",
       "      <td>Impossivel eu mandar meu filho de 4 anos para ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos</td>\n",
       "      <td>Absurdo , as escolas tem que se preparar para ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg</td>\n",
       "      <td>Eu por exemplo, tenho professores que já tem i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg</td>\n",
       "      <td>Já estamos quase em Agôsto, o ano já está term...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimento                                               text  Topic\n",
       "0        neg  Retorno de alunos às aulas presenciais deverá ...      0\n",
       "1        neg  O maior risco são os ônibus  eo metro e desde ...      0\n",
       "2        neg  olá a todos, venho aqui encarecidamente pedir ...      0\n",
       "3        neg  Justiça nega pedido de retorno das aulas prese...      0\n",
       "4        pos                               n aguento mais o EAD      0\n",
       "5        neg      É o certo né. EaD é um saco mas é mais seguro      0\n",
       "6        neg  Impossivel eu mandar meu filho de 4 anos para ...      1\n",
       "7        pos  Absurdo , as escolas tem que se preparar para ...      0\n",
       "8        neg  Eu por exemplo, tenho professores que já tem i...      1\n",
       "9        neg  Já estamos quase em Agôsto, o ano já está term...      1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4B0082;font-family:Comic Sans MS;\">Non-Negative Matrix Factorization (NMF)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimento</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>Retorno de alunos às aulas presenciais deverá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>O maior risco são os ônibus  eo metro e desde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>olá a todos, venho aqui encarecidamente pedir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Justiça nega pedido de retorno das aulas prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>n aguento mais o EAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimento                                               text\n",
       "0        neg  Retorno de alunos às aulas presenciais deverá ...\n",
       "1        neg  O maior risco são os ônibus  eo metro e desde ...\n",
       "2        neg  olá a todos, venho aqui encarecidamente pedir ...\n",
       "3        neg  Justiça nega pedido de retorno das aulas prese...\n",
       "4        pos                               n aguento mais o EAD"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_set = pd.read_csv(r'C:/Users/gabid/meus_desastres/NLTK/sentimentos.csv', sep=\";\")\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=stopwords)\n",
    "doc_term_matrix = tfidf_vect.fit_transform(data_set['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "    n_components=2, random_state=12, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating uma matrix de probabilidade de todas as palavras do documento\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=2, random_state=12)\n",
    "nmf.fit(doc_term_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alunos\n",
      "alunos\n",
      "pandemia\n",
      "papel\n",
      "filho\n",
      "ead\n",
      "pra\n",
      "filhos\n",
      "risco\n",
      "pra\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(tfidf_vect.get_feature_names()))\n",
    "    print(tfidf_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0, 35, 36, 18,  3, 34,  4, 13, 30], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colocar\n",
      "adultos\n",
      "risco\n",
      "setembro\n",
      "filhos\n",
      "ano\n",
      "retorno\n",
      "aulas\n",
      "escolas\n",
      "presenciais\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['colocar', 'adultos', 'risco', 'setembro', 'filhos', 'ano', 'retorno', 'aulas', 'escolas', 'presenciais']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['ficar', 'escola', 'muitas', 'dia', 'faculdade', 'volta', 'alunos', 'gente', 'aulas', 'dificuldade']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimento</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>Retorno de alunos às aulas presenciais deverá ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>O maior risco são os ônibus  eo metro e desde ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>olá a todos, venho aqui encarecidamente pedir ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Justiça nega pedido de retorno das aulas prese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>n aguento mais o EAD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neg</td>\n",
       "      <td>É o certo né. EaD é um saco mas é mais seguro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neg</td>\n",
       "      <td>Impossivel eu mandar meu filho de 4 anos para ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos</td>\n",
       "      <td>Absurdo , as escolas tem que se preparar para ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neg</td>\n",
       "      <td>Eu por exemplo, tenho professores que já tem i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neg</td>\n",
       "      <td>Já estamos quase em Agôsto, o ano já está term...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimento                                               text  Topic\n",
       "0        neg  Retorno de alunos às aulas presenciais deverá ...      0\n",
       "1        neg  O maior risco são os ônibus  eo metro e desde ...      1\n",
       "2        neg  olá a todos, venho aqui encarecidamente pedir ...      1\n",
       "3        neg  Justiça nega pedido de retorno das aulas prese...      0\n",
       "4        pos                               n aguento mais o EAD      0\n",
       "5        neg      É o certo né. EaD é um saco mas é mais seguro      0\n",
       "6        neg  Impossivel eu mandar meu filho de 4 anos para ...      1\n",
       "7        pos  Absurdo , as escolas tem que se preparar para ...      0\n",
       "8        neg  Eu por exemplo, tenho professores que já tem i...      1\n",
       "9        neg  Já estamos quase em Agôsto, o ano já está term...      0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = nmf.transform(doc_term_matrix)\n",
    "data_set['Topic'] = topic_values.argmax(axis=1)\n",
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
