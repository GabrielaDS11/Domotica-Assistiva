{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import unidecode\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "STOPWORDS = set(stopwords.words('portuguese'))\n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dados):\n",
    "    df = pd.read_csv(dados, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(text):\n",
    "    #transformar em letras minusculas\n",
    "    text = text.lower()\n",
    "    #retirar characters especiais\n",
    "    text = re.sub(r'\\W',' ',text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+',' ',text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem_Acentos(sentence):\n",
    "    texto_semAcentos = unicodedata.normalize(\"NFD\", sentence)\n",
    "    texto_semAcentos = texto_semAcentos.encode(\"ascii\", \"ignore\")\n",
    "    texto_semAcentos = texto_semAcentos.decode(\"utf-8\")\n",
    "    \n",
    "    return texto_semAcentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(text):\n",
    "    stemmer = SnowballStemmer(language='portuguese')\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_text=[]\n",
    "    for word in token_words:\n",
    "        stem_text.append(stemmer.stem(word))\n",
    "        stem_text.append(\" \")\n",
    "    return \"\".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Stemming2(text):\n",
    "    stemmer = RSLPStemmer()\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_text=[]\n",
    "    for word in token_words:\n",
    "        stem_text.append(stemmer.stem(word))\n",
    "        stem_text.append(\" \")\n",
    "    return \"\".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(texto_df, ngrams):\n",
    "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    vectorizer = CountVectorizer(min_df = 2, lowercase=True,ngram_range =(1,ngrams),stop_words = STOPWORDS, tokenizer = word_tokenize)\n",
    "    text_counts = vectorizer.fit_transform(texto_df)\n",
    "    \n",
    "    return text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(X):\n",
    "    \n",
    "    processed_features = X\n",
    "    vectorizer = TfidfVectorizer (max_features=500, min_df=2, max_df=0.8, stop_words=STOPWORDS)\n",
    "    processed_features = vectorizer.fit_transform(processed_features).toarray()\n",
    "    \n",
    "    return processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    matrix_X = X_train\n",
    "    \n",
    "    X_train = X_train.toarray()\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, matrix_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    matrix_X = X_train\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, matrix_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    forest = RandomForestClassifier(max_leaf_nodes=3, random_state=0)\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return score, report, forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return score, report, gnb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural(X_train, X_test, y_train, y_test,input_valor):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=50, activation='relu',input_dim = input_valor))\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    \n",
    "    summary=model.summary()\n",
    "    compiled = model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "    fitted = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=10)\n",
    "    \n",
    "    return summary, compiled, fitted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = loadData(\"tweet19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['texto'] = dataframe['texto'].apply(limpar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>mudou absolutamente nada paciência papo novo n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opinião mudou nada pessoas agindo vírus sido d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentivando pessoas irem praia plena pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>ônibus trens lotados tbm desde sempre praia po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>novo normal sei onde engraçado povo posando fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  mudou absolutamente nada paciência papo novo n...\n",
       "1  abertura das praias  opinião mudou nada pessoas agindo vírus sido d...\n",
       "2  abertura das praias  uol incentivando pessoas irem praia plena pand...\n",
       "3  abertura das praias  ônibus trens lotados tbm desde sempre praia po...\n",
       "4  abertura das praias  novo normal sei onde engraçado povo posando fo..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uol incentivando pessoas irem praia plena pandemia sim plena pandemia isolamento social necessário caso contrário sairemos nunca dessa situação fiquememcasa'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['texto'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts = bag_of_words(dataframe['texto'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = dataframe.iloc[:,1], dataframe.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abertura das praias', 'profissionais', 'transporte público',\n",
       "       'vacina', 'volta as aulas'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38x113 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 267 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, matrix_train = preprocessing(text_counts,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30x113 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 198 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 113)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 1 - Apenas Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "87.5 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.75      0.62      0.67         8\n",
      "weighted avg       1.00      0.88      0.92         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "0.0 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       2.0\n",
      "           3       0.00      0.00      0.00       3.0\n",
      "           4       0.00      0.00      0.00       3.0\n",
      "\n",
      "    accuracy                           0.00       8.0\n",
      "   macro avg       0.00      0.00      0.00       8.0\n",
      "weighted avg       0.00      0.00      0.00       8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                5700      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 7,290\n",
      "Trainable params: 7,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30 samples, validate on 8 samples\n",
      "Epoch 1/7\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 9.1143 - accuracy: 0.1333 - val_loss: 9.0311 - val_accuracy: 0.1250\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 0s 191us/step - loss: 7.4446 - accuracy: 0.1667 - val_loss: 7.5522 - val_accuracy: 0.1250\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 4.6070 - accuracy: 0.3333 - val_loss: 7.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 0s 239us/step - loss: 3.7941 - accuracy: 0.4000 - val_loss: 7.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 2.8545 - accuracy: 0.3667 - val_loss: 7.3110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 2.3736 - accuracy: 0.4000 - val_loss: 6.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 1.3360 - accuracy: 0.4000 - val_loss: 6.1095 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X_train, X_test, y_train, y_test, X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2 - Apenas TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.33150395, 0.36060372,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X = tfidf(X)\n",
    "processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, matrix_train = preprocessing2(processed_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    processed_X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "75.0 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.57      0.76      0.63        12\n",
      "weighted avg       0.68      0.75      0.69        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X_train2, X_test2, y_train2, y_test2)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "25.0 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.18      1.00      0.31         2\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.24      0.40      0.26        12\n",
      "weighted avg       0.11      0.25      0.13        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X_train2, X_test2, y_train2, y_test2)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 50)                5100      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 6,690\n",
      "Trainable params: 6,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 12 samples\n",
      "Epoch 1/7\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 7.8389 - accuracy: 0.1923 - val_loss: 8.7725 - val_accuracy: 0.1667\n",
      "Epoch 2/7\n",
      "26/26 [==============================] - 0s 268us/step - loss: 7.4401 - accuracy: 0.3077 - val_loss: 8.6545 - val_accuracy: 0.1667\n",
      "Epoch 3/7\n",
      "26/26 [==============================] - 0s 256us/step - loss: 7.1276 - accuracy: 0.3462 - val_loss: 9.2865 - val_accuracy: 0.1667\n",
      "Epoch 4/7\n",
      "26/26 [==============================] - 0s 270us/step - loss: 6.4345 - accuracy: 0.3462 - val_loss: 9.7826 - val_accuracy: 0.1667\n",
      "Epoch 5/7\n",
      "26/26 [==============================] - 0s 286us/step - loss: 5.7787 - accuracy: 0.3846 - val_loss: 8.8853 - val_accuracy: 0.1667\n",
      "Epoch 6/7\n",
      "26/26 [==============================] - 0s 307us/step - loss: 4.1481 - accuracy: 0.4615 - val_loss: 8.6806 - val_accuracy: 0.1667\n",
      "Epoch 7/7\n",
      "26/26 [==============================] - 0s 305us/step - loss: 2.5123 - accuracy: 0.6538 - val_loss: 7.8899 - val_accuracy: 0.0833\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X_train2, X_test2, y_train2, y_test2, X_train2.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 3 - Stemming e Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadData(\"tweet19.csv\")\n",
    "data.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'escolas públicas falta porta janela trinco ventilador papel sanitário água livros bibliotecas laboratório etc agora milagre brotará máscara álcool gel qm correrá risco adultos'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(limpar_texto)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'escol públic falt port janel trinc ventil papel sanitári águ livr bibliotec laboratóri etc agor milagr brot másc álcool gel qm corr risc adult '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(Stemming)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>mud absolut nad paciênc pap nov normal gal tá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opiniã mud nad pesso agind vírus sid debel bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentiv pesso irem pra plen pandem sim pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>ônibus trens lot tbm desd sempr pra pod woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>nov normal sei onde engrac pov pos fot másc ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  mud absolut nad paciênc pap nov normal gal tá ...\n",
       "1  abertura das praias  opiniã mud nad pesso agind vírus sid debel bra...\n",
       "2  abertura das praias  uol incentiv pesso irem pra plen pandem sim pl...\n",
       "3  abertura das praias  ônibus trens lot tbm desd sempr pra pod woman ...\n",
       "4  abertura das praias  nov normal sei onde engrac pov pos fot másc ac..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = data.iloc[:,1], data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y2 = labelencoder.fit_transform(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts2 = bag_of_words(data['texto'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test, matrix2_train = preprocessing(text_counts2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 135)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "75.0 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.44      0.50      0.46         8\n",
      "weighted avg       0.66      0.75      0.70         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "25.0 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      0.33      0.50         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.50      0.21      0.29         8\n",
      "weighted avg       0.62      0.25      0.35         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 50)                6800      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 8,390\n",
      "Trainable params: 8,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 8 samples\n",
      "Epoch 1/7\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 4.5145 - accuracy: 0.2000 - val_loss: 6.3333 - val_accuracy: 0.1250\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 0s 185us/step - loss: 2.9630 - accuracy: 0.2333 - val_loss: 4.5206 - val_accuracy: 0.1250\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 1.9373 - accuracy: 0.2667 - val_loss: 5.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 0s 199us/step - loss: 1.9296 - accuracy: 0.2667 - val_loss: 4.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 0s 166us/step - loss: 1.8999 - accuracy: 0.2667 - val_loss: 3.0929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 0s 250us/step - loss: 1.5558 - accuracy: 0.3000 - val_loss: 3.0627 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 1.5558 - accuracy: 0.3000 - val_loss: 3.0344 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X2_train, X2_test, y2_train, y2_test, X2_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste Sem acentuação e Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadData(\"tweet19.csv\")\n",
    "data.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'escolas públicas falta porta janela trinco ventilador papel sanitário água livros bibliotecas laboratório etc agora milagre brotará máscara álcool gel qm correrá risco adultos'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(limpar_texto)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadData(\"tweet19.csv\")\n",
    "data.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Em nossas escolas publicas falta porta, janela, trinco, ventilador, papel sanitario, agua, livros, bibliotecas, laboratorio etc Agora, por milagre, brotara mascara e alcool gel? Qm mais correra risco serao os adultos.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(sem_Acentos)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Impossivel eu mandar meu filho de 4 anos para escola , uma crianca dessa idade nao sabe os riscos que pode ocorrer caso ande sem mascara , divida lanche com os amigos, Nessa fase eles brincam muito juntos , se abracam, se beijam . Agora me diz ,como evita isso ,impossivel !!!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'impossivel mandar filho 4 anos escola crianca dessa idade nao sabe riscos pode ocorrer caso ande mascara divida lanche amigos nessa fase brincam juntos abracam beijam agora diz evita impossivel'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(limpar_texto)\n",
    "data['texto'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['texto'] = data['texto'].apply(Stemming2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'impossi mand filh 4 ano escol crianc dess idad nao sab risc pod ocorr cas and masc div lanch amig ness fas brinc junt abrac beij agor diz evit impossi '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>nao mud absolut nad ja nao pacienc pap nov nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opinia nao mud nad pesso esta agind viru sid d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentiv pesso ir prai plen pandem sim ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>onibu tr lot tbm desd sempr so prai nao pod wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>nov norm nao sei ond engrac pov pos fot masc a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  nao mud absolut nad ja nao pacienc pap nov nor...\n",
       "1  abertura das praias  opinia nao mud nad pesso esta agind viru sid d...\n",
       "2  abertura das praias  uol incentiv pesso ir prai plen pandem sim ple...\n",
       "3  abertura das praias  onibu tr lot tbm desd sempr so prai nao pod wo...\n",
       "4  abertura das praias  nov norm nao sei ond engrac pov pos fot masc a..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = data.iloc[:,1], data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y2 = labelencoder.fit_transform(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts2 = bag_of_words(data['texto'],3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test, matrix2_train = preprocessing(text_counts2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 146)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "75.0 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.44      0.50      0.46         8\n",
      "weighted avg       0.66      0.75      0.70         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "37.5 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      0.67      0.80         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.50      0.29      0.37         8\n",
      "weighted avg       0.62      0.38      0.47         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'estamos',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivéramos',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estávamos',\n",
       " 'estão',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'fui',\n",
       " 'fôramos',\n",
       " 'fôssemos',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'havemos',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houveram',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houvermos',\n",
       " 'houverá',\n",
       " 'houverão',\n",
       " 'houveríamos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvéramos',\n",
       " 'houvéssemos',\n",
       " 'há',\n",
       " 'hão',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'não',\n",
       " 'nós',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'são',\n",
       " 'só',\n",
       " 'também',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivéramos',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'tém',\n",
       " 'tínhamos',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'à',\n",
       " 'às',\n",
       " 'é',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 50)                7350      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 8,940\n",
      "Trainable params: 8,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 8 samples\n",
      "Epoch 1/7\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 4.8912 - accuracy: 0.2333 - val_loss: 6.5416 - val_accuracy: 0.3750\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 4.1398 - accuracy: 0.3333 - val_loss: 6.4531 - val_accuracy: 0.3750\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 0s 199us/step - loss: 3.9545 - accuracy: 0.4667 - val_loss: 6.3732 - val_accuracy: 0.3750\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 0s 300us/step - loss: 3.7964 - accuracy: 0.5000 - val_loss: 6.2908 - val_accuracy: 0.5000\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 3.6499 - accuracy: 0.6333 - val_loss: 6.2151 - val_accuracy: 0.6250\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 0s 399us/step - loss: 3.0710 - accuracy: 0.7000 - val_loss: 6.1485 - val_accuracy: 0.6250\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 0s 299us/step - loss: 3.2628 - accuracy: 0.7000 - val_loss: 6.0945 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X2_train, X2_test, y2_train, y2_test, X2_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
