{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "STOPWORDS = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dados):\n",
    "    df = pd.read_csv(dados, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_texto(text):\n",
    "    #transformar em letras minusculas\n",
    "    text = text.lower()\n",
    "    #retirar acentos\n",
    "    #retirar characters especiais\n",
    "    text = re.sub(r'\\W',' ',text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+',' ',text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "def Tokenize(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    return sentence\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(text):\n",
    "    stemmer = SnowballStemmer(language='portuguese')\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_text=[]\n",
    "    for word in token_words:\n",
    "        stem_text.append(stemmer.stem(word))\n",
    "        stem_text.append(\" \")\n",
    "    return \"\".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "def Lemmatization(sentence):    \n",
    "    for word in sentence:\n",
    "        print(word.text, word.lemma_)\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(texto_df, ngrams):\n",
    "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    vectorizer = CountVectorizer(min_df = 2, lowercase=True,ngram_range =(1,ngrams),stop_words = STOPWORDS, tokenizer = token.tokenize)\n",
    "    text_counts = vectorizer.fit_transform(texto_df)\n",
    "    \n",
    "    return text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(X):\n",
    "    \n",
    "    processed_features = X\n",
    "    vectorizer = TfidfVectorizer (max_features=500, min_df=2, max_df=0.8, stop_words=STOPWORDS)\n",
    "    processed_features = vectorizer.fit_transform(processed_features).toarray()\n",
    "    \n",
    "    return processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    matrix_X = X_train\n",
    "    \n",
    "    X_train = X_train.toarray()\n",
    "    X_test = X_test.toarray()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, matrix_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "    matrix_X = X_train\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, matrix_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    forest = RandomForestClassifier(max_leaf_nodes=3, random_state=0)\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return score, report, forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(X_train, X_test, y_train, y_test):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return score, report, gnb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural(X_train, X_test, y_train, y_test,input_valor):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=50, activation='relu',input_dim = input_valor))\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    \n",
    "    summary=model.summary()\n",
    "    compiled = model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "    fitted = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=10)\n",
    "    \n",
    "    return summary, compiled, fitted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = loadData(\"tweet19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['texto'] = dataframe['texto'].apply(limpar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>mudou absolutamente nada paciência papo novo n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opinião mudou nada pessoas agindo vírus sido d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentivando pessoas irem praia plena pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>ônibus trens lotados tbm desde sempre praia po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>novo normal sei onde engraçado povo posando fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  mudou absolutamente nada paciência papo novo n...\n",
       "1  abertura das praias  opinião mudou nada pessoas agindo vírus sido d...\n",
       "2  abertura das praias  uol incentivando pessoas irem praia plena pand...\n",
       "3  abertura das praias  ônibus trens lotados tbm desde sempre praia po...\n",
       "4  abertura das praias  novo normal sei onde engraçado povo posando fo..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uol incentivando pessoas irem praia plena pandemia sim plena pandemia isolamento social necessário caso contrário sairemos nunca dessa situação fiquememcasa'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['texto'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'at', 'est', 'estiv', 'f', 'h', 'houv', 'j', 'm', 'n', 'nhamos', 'ramos', 's', 'ser', 'ssemos', 't', 'tamb', 'ter', 'tiv', 'vamos', 'voc'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "text_counts = bag_of_words(dataframe['texto'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = dataframe.iloc[:,1], dataframe.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abertura das praias', 'profissionais', 'transporte público',\n",
       "       'vacina', 'volta as aulas'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38x133 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, matrix_train = preprocessing(text_counts,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30x133 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 249 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 133)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 1 - Apenas Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "87.5 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.75      0.62      0.67         8\n",
      "weighted avg       1.00      0.88      0.92         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "25.0 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      0.33      0.50         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.50      0.21      0.29         8\n",
      "weighted avg       0.62      0.25      0.35         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                6700      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 8,290\n",
      "Trainable params: 8,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30 samples, validate on 8 samples\n",
      "Epoch 1/7\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 6.6808 - accuracy: 0.2667 - val_loss: 11.2903 - val_accuracy: 0.2500\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 0s 166us/step - loss: 6.2560 - accuracy: 0.3333 - val_loss: 9.8559 - val_accuracy: 0.2500\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 5.2021 - accuracy: 0.5000 - val_loss: 9.5394 - val_accuracy: 0.1250\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 0s 166us/step - loss: 4.9735 - accuracy: 0.5333 - val_loss: 9.3827 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 0s 201us/step - loss: 4.8118 - accuracy: 0.5333 - val_loss: 9.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 0s 199us/step - loss: 4.3397 - accuracy: 0.5333 - val_loss: 9.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 3.8659 - accuracy: 0.5333 - val_loss: 9.1761 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X_train, X_test, y_train, y_test, X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2 - Apenas TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.33150395, 0.36060372,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X = tfidf(X)\n",
    "processed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, matrix_train = preprocessing2(processed_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    processed_X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "75.0 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.57      0.76      0.63        12\n",
      "weighted avg       0.68      0.75      0.69        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X_train2, X_test2, y_train2, y_test2)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "25.0 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.18      1.00      0.31         2\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.24      0.40      0.26        12\n",
      "weighted avg       0.11      0.25      0.13        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X_train2, X_test2, y_train2, y_test2)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 50)                5100      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 6,690\n",
      "Trainable params: 6,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 12 samples\n",
      "Epoch 1/7\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.8162 - accuracy: 0.1154 - val_loss: 3.3479 - val_accuracy: 0.4167\n",
      "Epoch 2/7\n",
      "26/26 [==============================] - 0s 303us/step - loss: 5.0498 - accuracy: 0.1923 - val_loss: 3.2998 - val_accuracy: 0.2500\n",
      "Epoch 3/7\n",
      "26/26 [==============================] - 0s 269us/step - loss: 3.9699 - accuracy: 0.3077 - val_loss: 3.2895 - val_accuracy: 0.3333\n",
      "Epoch 4/7\n",
      "26/26 [==============================] - 0s 345us/step - loss: 3.6580 - accuracy: 0.3462 - val_loss: 3.3805 - val_accuracy: 0.4167\n",
      "Epoch 5/7\n",
      "26/26 [==============================] - 0s 258us/step - loss: 3.5189 - accuracy: 0.3462 - val_loss: 4.1492 - val_accuracy: 0.4167\n",
      "Epoch 6/7\n",
      "26/26 [==============================] - 0s 345us/step - loss: 3.2681 - accuracy: 0.3846 - val_loss: 4.1327 - val_accuracy: 0.4167\n",
      "Epoch 7/7\n",
      "26/26 [==============================] - 0s 230us/step - loss: 3.3187 - accuracy: 0.3846 - val_loss: 4.1101 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X_train2, X_test2, y_train2, y_test2, X_train2.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 3 - Stemming e Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadData(\"tweet19.csv\")\n",
    "data.columns = ['assunto','texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'escolas públicas falta porta janela trinco ventilador papel sanitário água livros bibliotecas laboratório etc agora milagre brotará máscara álcool gel qm correrá risco adultos'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(limpar_texto)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'escol públic falt port janel trinc ventil papel sanitári águ livr bibliotec laboratóri etc agor milagr brot másc álcool gel qm corr risc adult '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texto'] = data['texto'].apply(Stemming)\n",
    "data['texto'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>mud absolut nad paciênc pap nov normal gal tá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opiniã mud nad pesso agind vírus sid debel bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentiv pesso irem pra plen pandem sim pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>ônibus trens lot tbm desd sempr pra pod woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>nov normal sei onde engrac pov pos fot másc ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  mud absolut nad paciênc pap nov normal gal tá ...\n",
       "1  abertura das praias  opiniã mud nad pesso agind vírus sid debel bra...\n",
       "2  abertura das praias  uol incentiv pesso irem pra plen pandem sim pl...\n",
       "3  abertura das praias  ônibus trens lot tbm desd sempr pra pod woman ...\n",
       "4  abertura das praias  nov normal sei onde engrac pov pos fot másc ac..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = data.iloc[:,1], data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y2 = labelencoder.fit_transform(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'at', 'est', 'estiv', 'f', 'h', 'houv', 'j', 'm', 'n', 'nhamos', 'ramos', 's', 'ser', 'ssemos', 't', 'tamb', 'ter', 'tiv', 'vamos', 'voc'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "text_counts2 = bag_of_words(data['texto'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test, matrix2_train = preprocessing(text_counts2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 154)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Naive Bayes: \n",
      "75.0 %\n",
      "Report Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.40      0.40      0.40         8\n",
      "weighted avg       0.75      0.75      0.75         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb_score, gnb_report, gnb  = gaussian(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Naive Bayes: \")\n",
    "print(gnb_score,\"%\")\n",
    "print(\"Report Naive Bayes: \")\n",
    "print(gnb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia Random Forest: \n",
      "12.5 %\n",
      "Report Random Forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.12         8\n",
      "   macro avg       0.25      0.12      0.17         8\n",
      "weighted avg       0.25      0.12      0.17         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_score, forest_report, forest  = randomForest(X2_train, X2_test, y2_train, y2_test)\n",
    "print(\"Accuracia Random Forest: \")\n",
    "print(forest_score,\"%\")\n",
    "print(\"Report Random Forest: \")\n",
    "print(forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 50)                7750      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 9,340\n",
      "Trainable params: 9,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 8 samples\n",
      "Epoch 1/7\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 8.1284 - accuracy: 0.2000 - val_loss: 9.7746 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/7\n",
      "30/30 [==============================] - 0s 233us/step - loss: 7.2665 - accuracy: 0.2333 - val_loss: 9.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 6.2005 - accuracy: 0.3333 - val_loss: 8.3305 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/7\n",
      "30/30 [==============================] - 0s 266us/step - loss: 5.2660 - accuracy: 0.4000 - val_loss: 8.2033 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/7\n",
      "30/30 [==============================] - 0s 201us/step - loss: 4.6549 - accuracy: 0.4667 - val_loss: 8.2072 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/7\n",
      "30/30 [==============================] - 0s 266us/step - loss: 4.3384 - accuracy: 0.5333 - val_loss: 8.2397 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/7\n",
      "30/30 [==============================] - 0s 200us/step - loss: 3.9031 - accuracy: 0.5667 - val_loss: 6.8722 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "summary, compiled, fitted = neural(X2_train, X2_test, y2_train, y2_test, X2_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
