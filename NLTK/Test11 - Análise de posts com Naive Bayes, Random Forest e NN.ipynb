{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet19.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>Não mudou absolutamente NADA!!! Eu já não tenh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>Na minha opinião, não mudou nada, as pessoas e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>Uol incentivando as pessoas irem para a praia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>Nos ônibus e trens lotados tbm, desde sempre.S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>novo normal não sei onde... O mais engraçado e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>A uol deveria publicar algo mais produtivo do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>Daqui exatas 3 semanas vamos ter um aumento na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>E nós se fode aqui né,sem aula,sem poder traba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Irão colocar as vidas de crianças e familiares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>O meu filho tem um pouquinho mais de dificulda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Impossivel eu mandar meu filho de 4 anos para ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Sou professora e geralmente quando eu viro as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Em nossas escolas públicas falta porta, janela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Muitas vezes, o Enem é a oportunidade para as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Eu por exemplo, tenho professores que já tem i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>volta as aulas</td>\n",
       "      <td>Já estamos quase em Agôsto, o ano já está term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vacina</td>\n",
       "      <td>A fala do presidente @jairbolsonaro sobre não ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Cada um que cuide da sua vida e da sua saúde. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Se isso atingisse apenas vc, eu concordaria. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Cadê a comprovação científica dessa Vachina? N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Logo os que estarão vacinados, estarão também ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Muito bom! Tô me lixando para o coletivo. Tenh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Essa lei não torna a vacina compulsória. Dizer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Eu tbm acho não sei qual é dessas vacinas pois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vacina</td>\n",
       "      <td>Me vacino só se for da China, prq dai não tem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>O maior risco são os ônibus  eo metro e desde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>@Uol deveria mostrar os ônibus lotados e outro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>É impressionante que, nos últimos 6 meses, enq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>O curioso é que as pessoas ficam impressionada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>Pela primeira vez na quarentena ontem tive que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>impossível de andar nesses onibus lotados, qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transporte público</td>\n",
       "      <td>pessoa está espirrando e ainda veio sentar no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>“Embora nossos profissionais de saúde, enferme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>“Nossos profissionais de saúde são heróis. Est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>Chart with upwards trend “Com base nesses dado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>“Esses números são alarmantes e levantam uma q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>“Com um aumento no número de funcionários Woma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>profissionais</td>\n",
       "      <td>“Quando os países expandem suas forças de trab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                assunto                                              texto\n",
       "0   abertura das praias  Não mudou absolutamente NADA!!! Eu já não tenh...\n",
       "1   abertura das praias  Na minha opinião, não mudou nada, as pessoas e...\n",
       "2   abertura das praias  Uol incentivando as pessoas irem para a praia ...\n",
       "3   abertura das praias  Nos ônibus e trens lotados tbm, desde sempre.S...\n",
       "4   abertura das praias  novo normal não sei onde... O mais engraçado e...\n",
       "5   abertura das praias  A uol deveria publicar algo mais produtivo do ...\n",
       "6   abertura das praias  Daqui exatas 3 semanas vamos ter um aumento na...\n",
       "7   abertura das praias  E nós se fode aqui né,sem aula,sem poder traba...\n",
       "8        volta as aulas  Irão colocar as vidas de crianças e familiares...\n",
       "9        volta as aulas  O meu filho tem um pouquinho mais de dificulda...\n",
       "10       volta as aulas  Impossivel eu mandar meu filho de 4 anos para ...\n",
       "11       volta as aulas  Sou professora e geralmente quando eu viro as ...\n",
       "12       volta as aulas  Em nossas escolas públicas falta porta, janela...\n",
       "13       volta as aulas  Muitas vezes, o Enem é a oportunidade para as ...\n",
       "14       volta as aulas  Eu por exemplo, tenho professores que já tem i...\n",
       "15       volta as aulas  Já estamos quase em Agôsto, o ano já está term...\n",
       "16               vacina  A fala do presidente @jairbolsonaro sobre não ...\n",
       "17               vacina  Cada um que cuide da sua vida e da sua saúde. ...\n",
       "18               vacina  Se isso atingisse apenas vc, eu concordaria. M...\n",
       "19               vacina  Cadê a comprovação científica dessa Vachina? N...\n",
       "20               vacina  Logo os que estarão vacinados, estarão também ...\n",
       "21               vacina  Muito bom! Tô me lixando para o coletivo. Tenh...\n",
       "22               vacina  Essa lei não torna a vacina compulsória. Dizer...\n",
       "23               vacina  Eu tbm acho não sei qual é dessas vacinas pois...\n",
       "24               vacina  Me vacino só se for da China, prq dai não tem ...\n",
       "25   transporte público  O maior risco são os ônibus  eo metro e desde ...\n",
       "26   transporte público  @Uol deveria mostrar os ônibus lotados e outro...\n",
       "27   transporte público  É impressionante que, nos últimos 6 meses, enq...\n",
       "28   transporte público  O curioso é que as pessoas ficam impressionada...\n",
       "29   transporte público  Pela primeira vez na quarentena ontem tive que...\n",
       "30   transporte público   impossível de andar nesses onibus lotados, qu...\n",
       "31   transporte público   pessoa está espirrando e ainda veio sentar no...\n",
       "32        profissionais  “Embora nossos profissionais de saúde, enferme...\n",
       "33        profissionais  “Nossos profissionais de saúde são heróis. Est...\n",
       "34        profissionais  Chart with upwards trend “Com base nesses dado...\n",
       "35        profissionais  “Esses números são alarmantes e levantam uma q...\n",
       "36        profissionais  “Com um aumento no número de funcionários Woma...\n",
       "37        profissionais  “Quando os países expandem suas forças de trab..."
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processamento\n",
    "#REPLACE_BY_SPACE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "#BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['assunto','texto']\n",
    "def limpar_texto(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W',' ',text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+',' ',text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['texto'] = df['texto'].apply(limpar_texto)\n",
    "df['texto'] = df['texto'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assunto</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>mudou absolutamente nada paciência papo novo n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>opinião mudou nada pessoas agindo vírus sido d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>uol incentivando pessoas irem praia plena pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>ônibus trens lotados tbm desde sempre praia po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abertura das praias</td>\n",
       "      <td>novo normal sei onde engraçado povo posando fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               assunto                                              texto\n",
       "0  abertura das praias  mudou absolutamente nada paciência papo novo n...\n",
       "1  abertura das praias  opinião mudou nada pessoas agindo vírus sido d...\n",
       "2  abertura das praias  uol incentivando pessoas irem praia plena pand...\n",
       "3  abertura das praias  ônibus trens lotados tbm desde sempre praia po...\n",
       "4  abertura das praias  novo normal sei onde engraçado povo posando fo..."
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras únicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uol incentivando pessoas irem praia plena pandemia sim plena pandemia isolamento social necessário caso contrário sairemos nunca dessa situação fiquememcasa'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texto'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisa-se retirar os acentos\n",
    "#import unidecode\n",
    "#import unicodedata\n",
    "\n",
    "#sem_acentos = unidecode.unidecode(df['texto'])\n",
    "#print(sem_acentos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "#from nltk.stem import PorterStemmer\n",
    "#ps = PorterStemmer()\n",
    "#stemmed_words= ps.stem(X)\n",
    "#print(df['texto'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabid\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['amos', 'at', 'est', 'estiv', 'f', 'h', 'houv', 'j', 'm', 'n', 'nhamos', 'ramos', 's', 'ser', 'ssemos', 't', 'tamb', 'ter', 'tiv', 'vamos', 'voc'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#Bag of words and Tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#remover simbolos e números\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 2, lowercase=True,ngram_range =(1,1),stop_words = STOPWORDS, tokenizer = token.tokenize)\n",
    "text_counts = vectorizer.fit_transform(df['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.iloc[:,1], df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abertura das praias', 'profissionais', 'transporte público',\n",
       "       'vacina', 'volta as aulas'], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<38x111 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 288 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_counts, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30x111 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 212 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Acuracia: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes com somente Bag of Words\n",
    "naivebayes = GaussianNB()\n",
    "naivebayes.fit(X_train, y_train)\n",
    "naive_predicted = naivebayes.predict(X_test)\n",
    "print(\"Gaussian Acuracia:\",accuracy_score(y_test, naive_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Acuracia: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Arvore de decisão com somente Bag of Words\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)\n",
    "forest_predict = text_classifier.predict(X_test)\n",
    "print(\"Random Forest Acuracia:\",accuracy_score(y_test, forest_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Generation using TF-IDF\n",
    "processed_features = X\n",
    "vectorizer = TfidfVectorizer (max_features=500, min_df=2, max_df=0.8, stop_words=STOPWORDS)\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    processed_features, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Acuracia: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "naivebayes.fit(X_train2, y_train2)\n",
    "naive_predicted = naivebayes.predict(X_test2)\n",
    "print(\"Gaussian Acuracia:\",accuracy_score(y_test2, naive_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Acuracia: 0.25\n"
     ]
    }
   ],
   "source": [
    "#Arvore de decisão\n",
    "text_classifier.fit(X_train2, y_train2)\n",
    "forest_predict = text_classifier.predict(X_test2)\n",
    "print(\"Random Forest Acuracia:\",accuracy_score(y_test2, forest_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test2,forest_predict))\n",
    "#print(classification_report(y_test2,forest_predict))\n",
    "#print(accuracy_score(y_test2, florest_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rede Neural\n",
    "model = Sequential()\n",
    "model.add(Dense(units=70, activation='relu',input_dim = 100))\n",
    "model.add(Dense(units=30, activation='relu'))\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dense(units=5, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 30)                2130      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 9,745\n",
      "Trainable params: 9,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 100), (12, 100))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 12 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 4.6312 - accuracy: 0.1923 - val_loss: 3.2346 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 461us/step - loss: 4.2538 - accuracy: 0.3077 - val_loss: 3.3305 - val_accuracy: 0.2500\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 307us/step - loss: 3.1272 - accuracy: 0.5000 - val_loss: 4.1963 - val_accuracy: 0.2500\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 306us/step - loss: 2.6015 - accuracy: 0.5000 - val_loss: 4.8667 - val_accuracy: 0.2500\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 382us/step - loss: 1.6322 - accuracy: 0.5000 - val_loss: 4.6937 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e92af17288>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, validation_data=(X_test2, y_test2), epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
